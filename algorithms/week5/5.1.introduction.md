# Introduction

- Recursion
- Trees
- Binary search trees
- Maps
- Sets
- Hash tables

# 5.2 Recursion

Functions, recursive or not, when called produce a structure called a frame to store information about that particular function call. They typically store data such as its namespace, parameters, local variables and also which command in the body it is running.

This gets halted when a nested function call is made and the frame records where to pick back off after that nested function call is finished executing. There is a **different** frame for each function call even if it was for the same one.

## Reading

### Analysing recursive functions

#### Computing factorials

5! = 5 x 4 x 3 x 2 x 1 = 120

Pretty easy to turn this into an algorithm using recursion

```py
def factorialise(value):
  if value == 0
    return 1
  return value * factorialise(value - 1)
```
##### Code analysis

- We call the function from within the function but with a different argument.
- There's that guard clause to stop us calling the function forever.
- This could have easily been implemented with a loop and there's **no** particular advantage for choosing recursion over it.

##### Algorithm analysis

- There are n + 1 activations of our function. (n + 1 because we're calling it from n -> 0)
- Ignoring constants we're left with **O(n)**.

#### Drawing an English Ruler

Fractals for babies. Fractal in the sense that at different levels of magnification the structure repeats itself. power of 10s

We could represent the lines on a ruler using '-' where the more significant values are longer '---' and they get shorter at the mid points and the mid points of those mid points.
```
--- 3
-
--
-
--- 2
-
--
-
--- 1
-
--
-
--- 0
```

> I did pretty [good!](/algorithms/week5/python_/english_ruler.py)

##### Algorithm analysis

The draw_interval function is where the recursion takes place. As we recursively call twice per frame

2^c^ - 1 lines of output

#### Binary Search

When data is sorted you can cut the search pool in half each step making it way more efficient than going through every single element and checking it off the list in the worst case. We're looking at O(log n) instead of O(n).

Searching through a billion elements only takes 30 steps ;)

#### File systems

![Example file system](/algorithms/week5/Screenshot%202025-06-07%20at%2019.44.57.png)

[Example code](/algorithms/week5/python_/disk_usage.py)

- Numbers outside of the box represent cumulative disk usage of that directory along with its children. Numbers in the box represent the disk usage but for that directory and without its child directories.

- Uses Python's OS Module

##### Pseudo

input: "String of current file path"
output: "number showing the full disc usage of current file path and all descendants of our directory.

```
def disk_usage(path):
  total = size of path
  if path is directory:
    get file/directory names in current directory
    for filename in directory:
      childpath = directory + filename
      total += disk_usage(childpath)
  return total
```

##### Recursion Trace

We can print out the disk usage for each item giving us a sort of report. This matches **du** function in the terminal where it lists out all the directories.

## Bad Recursion

### Unique element problem

Book is covering element uniqueness problem and using recursion.

Algorith takes the array and a start and stop for the slice. This lets us access a slice like this slice[start:stop]

```py
def unique3(S, start, stop)
  if stop - start <= 1:
      return True
  elif not unique(S, start, stop - 1):  # ← 1st recursive call
      return False
  elif not unique(S, start + 1, stop):  # ← 2nd recursive call (only if 1st returned True)
      return False
  else:
      return S[start] != S[stop - 1]

```
- n = 1: When n is 1 we know the slice is unique and return True.
- n >= 2: We need to check if first n-1 cases are unique, the last n-1 cases are unique, and the first and last elements are different.
---

The non-recursive operations run at O(1) so we can ignore those as the running time will be proportional to the number of recursive invocations

In the worst case we're calling the function recursively twice per frame. This makes it O(2^n^) which is horrendous time complexity. Could do with some **memoisation** where we cache some data in order to not expensively compute that shi-.

> Important to note this algorithm doesn't suck because of recursion. It sucks because recursion was used poorly

### Fibonacci

Recursion can be poorly implemented here as well. Remember it's the sequence where we add the last 2 numbers of the sequence to get the next one.

0 + 1 = 1
1 + 1 = 2
1 + 2 = 3
2 + 3 = 5
3 + 5 = 8

```
  F0 = 0
  F1 = 1
  Fn = Fn−2 +Fn−1 for n > 1
```
You can immediately tell from the pseudo code we're working exponentially as with each step we're squaring it. O(n^2^)

```py
def bad_fibonacci(n):
  # First if covers the first 2 cases listed above.
  if n <= 1:
    return n
  # Covers the n >= 2 cases
  return bad_fibonacci(n - 1) + bad_fibonacci(n - 2)
```

#### Good Fibonacci

Can have the function return 2 values to keep it to linear recursion. 

```py
def good_fibonacci(n):
  if n == 0:
    return (0, 1) # Start off the sequence
  else:
    a, b = good_fibonacci(n - 1)
    return (b, a + b)
```
##### Trace
Trace when n = 10
- It first generates 10 calls where n decreases by 1.
10, 9, 8, ..., 1, 0

- When it hits 0 it returns (0, 1)
- That gets unpacked by the second last call so a = 0 and b = 1
- Then returns (b, a + b) or (0, 1 + 0)
- Third last call unpacks that so returns (1, 1 + 1) which is (1, 2)
- Fourth last call unpacks and returns (2, 3)
- 5th returns (3, 5)
- 6th last returns (5, 8)

> Overall the guy who came up with this is a genius. **O(n)**

## Maximum Recursion Depth

- Python has a limit set to 1000. Can modify this in the settings. Get max recursion depth error if this is exceeded.

# 4.4 Further Examples

Recall that recursive function that only calls on itself once per frame is **linear**

Recursive function that calls itself twice per frame is **binary** recursion

More than that is **multiple recursion**. An example is when we're trying to calculate every permutation for a puzzle for instance.

## Linear recursion

Binary search is a case of linear recursion. Even though in the code it looks like there are 2 calls, they are branched and would never happen in the same frame.

You gotta remember that binary search is O(log(n)) and the recursive depth **doesn't** necessarily provide asymptotic analysis of the running time.

The recursion trace here appears as a single sequence of calls.

> I kinda skipped through the other examples

## 4.5 Designing recursive function

- First test for base cases
- If not base case then we perform recursive calls. These recursive calls should eventually get to the base case.