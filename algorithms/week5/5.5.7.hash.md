Got it! Here's a **cleaned-up and focused version** of your notes on **hash functions, hash tables, and collision handling**, with all the **set-related content removed**, but retaining and integrating relevant material from the **earlier hashing notes** I wrote for you.

---

# ðŸ” Hash Functions, Hash Tables & Collision Handling

---

## ðŸ“¦ Hash Tables: Overview

A **hash table** is a data structure that stores key-value pairs (or keys only) by computing an index from the key using a **hash function**. The table is typically a fixed-size array, and the goal is to support **fast insertion, lookup, and deletion** â€” ideally in **O(1)** time.

---

## ðŸ”¢ Hash Functions

A **hash function** takes a key (e.g. an int or string) and maps it to an **integer index** within the bounds of the hash table.

### âœ… Requirements for a Good Hash Function:

* **Deterministic**: Same input â†’ same output
* **Uniform**: Distributes keys evenly to reduce collisions
* **Efficient**: Fast to compute
* **Low collision rate**: Different keys map to different indices (ideally)

---

## ðŸ” Examples

### ðŸ”¸ Integer keys

Use modulo (`%`) with table size:

```python
key = 42
index = 42 % 11  # â†’ 9
```

### ðŸ”¸ String keys

Strings must be converted to integers first. A basic method is to sum ASCII values of characters:

```python
def simple_hash(s, table_size):
    return sum(ord(char) for char in s) % table_size
```

More advanced hash functions (e.g., Pythonâ€™s built-in `hash()`) also incorporate randomness and better bit-distribution.

---

## âš ï¸ Collisions

A **collision** occurs when two different keys map to the same index.

### Collision Handling Strategies:

1. **Separate Chaining**
2. **Open Addressing**

---

## ðŸŒ¿ 1. Separate Chaining

Each index of the hash table contains a **linked list (or similar structure)**. All keys that hash to the same index are stored in that list.

### How it works:

* Inserted key goes to the **front** of the list.
* Lookup and delete involve scanning that list.

### Pros:

* Simple to implement
* Can handle high load factors (even > 1)
* Deletion is straightforward

### Cons:

* Uses extra memory (for linked lists)
* Slightly worse cache performance due to indirection

### Time Complexity (average):

* Insert: O(1)
* Lookup: O(1)
* Delete: O(1)

---

## ðŸ“ Load Factor (Î»)

The **load factor** is a key metric for hash table performance:

$$
\lambda = \frac{n}{s}
$$

Where:

* `n` = number of stored elements
* `s` = number of slots (table size)

### Guideline:

* **Î» â‰ˆ 0.7â€“0.8** is usually optimal
* High Î» = memory efficient but more collisions
* Low Î» = fewer collisions but wastes memory

---

## ðŸ§® 2. Open Addressing

Instead of chaining, **all elements are stored in the array itself**. When a collision happens, it searches for the next available slot using a **probing method**.

### Probing Methods:

* **Linear Probing**: Try next slot, then next (wraps around if needed)
* **Quadratic Probing**: Try iÂ²-th offset (less clustering)
* **Double Hashing**: Use a second hash function to compute jump distance

### Deletion uses **tombstones** (special markers for deleted items) to preserve search chains.

### Pros:

* More cache-friendly
* No extra memory needed for linked lists

### Cons:

* Clustering degrades performance
* Needs careful probing design
* Deletion is more complex

### Performance:

Average case:

$$
\text{O}\left(\frac{1}{1 - \lambda}\right)
$$

As Î» â†’ 1, performance deteriorates **sharply**.

---

## ðŸ” Resizing & Rehashing

To maintain performance, hash tables **resize** when the load factor exceeds a threshold.

### Process:

1. Double the table size (usually to next prime number)
2. Re-hash all existing keys
3. Insert into new table

### Time Complexity:

* Resizing: O(n)
* Amortized over many operations, so average insert remains O(1)

---

## ðŸ§  Summary: Chaining vs Open Addressing

| Feature             | Separate Chaining               | Open Addressing            |
| ------------------- | ------------------------------- | -------------------------- |
| Memory use          | Extra (linked structures)       | Compact (array only)       |
| Load factor support | Î» > 1 allowed                   | Î» < 1 mandatory            |
| Cache performance   | Worse (linked list indirection) | Better (array-based)       |
| Deletion            | Simple                          | Tricky (tombstones)        |
| Resize strategy     | Less frequent                   | Requires frequent resizing |

---

## ðŸ§ª Final Notes

* Hash tables shine in **fast access**, but collision handling is key to performance.
* **Load factor and hashing quality** directly affect lookup efficiency.
* For many general-purpose use cases, **separate chaining** is robust and easier to manage.
* **Open addressing** is more memory-efficient and cache-optimized but trickier when deletions and high load factors are involved.

---

Let me know if you'd like diagrams for probing techniques or hash table internals!
