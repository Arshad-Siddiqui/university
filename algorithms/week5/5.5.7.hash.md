# Hash Functions

Takes a key and maps it to an index in a hash table.

We use % mod operator to decide how keys are laid out on the table. It typically distributes them immediately.

## int key

For example a hash table with 11 slots, we can do key % 11 and the remainder decides which slot the key goes in.

hash(42) = 42 % 11 = 9

Key 42 goes ot index 9 in the hash table.

## String key

Need hash function to turn a string into numeric value. Can some ascii values and do modulo % of the table size.

## Good Hash Function

- Keys distributed evenly across hash table.
- Avoids collisions where keys are mapped to the same index.
- Avoids clustering where keys are not uniformly distributed.
- Also deterministic so the same function should take an input and give the same output consistently.

# Separate chaining

Handles colisions where 2 different keys hash to the same index of the table.

Uses data structure similar to a linked list to store multiple keys at the same index of the hash table.

When a new key is added and there is a clash it simply gets added to the **front** of the linked list.

## Summary (From what i can tell)

A hash table is like an array that points to linked lists. Hash functions ensure that new keys get distributed randomly (fairly evenly) so certain hash indexes aren't too full.

When keys hash to the same position they get added to the front of the linked list.

When searching for a key, you run the hash function on it and then traverse the list that pops up. If it isn't there then you report the key as not present.

This is efficient as you don't have to check most of the data when searching for a key.

## Load factor

Measures how full the hash table is.

loadFactor(λ) = number of elements in table / size of array

λ = n / s

**0.7-0.8** is a good range to keep it.

Important to keep the load factor balanced. A high load factor is more memory efficient but means you're traversing longer lists and you're more likely to have collisions.

A low load factor means there are loads of indexes in the hash table that are empty which is a waste of memory.

## Performance

A lot of this is thanks to new elements being added to front of linked list.

Adding -> O(1)
Searching -> O(1)
Deleting -> O(1)
Resizing -> O(n)

# Open Addressing

Is an alternative to separate chaining. Where an index is already full we do some **probing**.

Linear probing is where we keep checking for the next available slot linearly.

So if index 5 is full, we check index 6 and so on until we find it a nice snuggly home.

If needs be, probing can wrap around back to the front of the indexes.

One bad thing about probing is that it causes clustering of full indexes. This affects searches as you need to probe around for each search.

Deletions leave tomb stones which can get replaced in insertions or left there to aid probing.  

## Performance

In general O(1/(1-λ))

Lambda is load factor. As load factor increases the efficiency of these operations decreases.

Quadratic probing and double hashing helps stop data from clustering.

Compared to separate chaining it is very memory efficient but isn't very good at managing high load factors.

Deletion better with separate chaining as you don't have to go probing potentially the entire list.

In the end you have to look at your use case before deciding on a collision handler.