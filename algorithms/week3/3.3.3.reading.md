Hereâ€™s a cleaned-up and professional version of your notes, written in polished markdown:

---

# Asymptotic Analysis and Big O Notation

In asymptotic analysis, we focus on how an algorithmâ€™s **performance scales** as the size of its input increases, rather than counting exact operations. We simplify all primitive operations as taking constant time â€” **O(1)** â€” and concentrate on growth patterns driven by constructs like loops and recursion.

> ðŸ“º Helpful [video explanation](https://www.youtube.com/watch?v=0oDAlMwTrLo)

---

## What Is an Asymptote?

An **asymptote** is a line a function gets closer and closer to as the input size grows, without ever actually touching it. In algorithm analysis, this corresponds to the **highest-order term** in a function.

Example:

```
f(n) = nÂ² + 2n + 6
```

In Big O analysis, we focus only on the dominant term:

```
f(n) is O(nÂ²)
```

![Asymptote diagram](image-2.png)

Some algorithms may start fast but approach a steep curve as inputs grow. Asymptotic analysis helps us **compare algorithms at scale**.

---

## Big-O Notation (O)

Used to describe an **upper bound** on an algorithmâ€™s growth.

If we say:

```
f(n) â‰¤ cÂ·g(n) for all n â‰¥ nâ‚€
```

We write:

```
f(n) is O(g(n))
```

This means that beyond a certain input size `nâ‚€`, `g(n)` is a reliable worst-case growth ceiling for `f(n)`.

![Graph of f(n) vs cg(n)](image-1.png)

---

### How to Use Big O

* **Ignore constants** and **lower-order terms**
* Focus on the dominant factor driving growth

Example:

```
f(n) = 3nâ¹ + 9nÂ³ + 12
```

```
f(n) is O(nâ¹)
```

Even though `O(nÂ¹â°â°)` would also technically be correct, itâ€™s unhelpful â€” aim to simplify while staying precise.

---

## Other Common Notations

### Î© (Big Omega)

Describes a **lower bound** â€” how good an algorithm can get.

```
f(n) is Î©(g(n))
```

### Î˜ (Big Theta)

A **tight bound** â€” both the upper and lower bounds match.

```
f(n) is Î˜(g(n)) âŸº f(n) is O(g(n)) and f(n) is Î©(g(n))
```

---

## Big O: Limitations

Big O is extremely useful, but **not perfect**. It hides:

* Constant factors
* Lower-order terms

Example:

```
f(n) = 10Â¹â°â°Â·n â†’ O(n)
g(n) = nÂ² â†’ O(nÂ²)
```

Even though `f(n)` is O(n), in practice it may be worse than `g(n)` for all reasonable `n`.

---

## Constant Time Operations â€” O(1)

Some operations remain fast **regardless of input size**:

```python
len(data)
```

In Python, `len()` is O(1) because list length is stored.

Accessing an index is also O(1), thanks to contiguous memory:

```text
memory_address + (index Ã— cell_size) = exact element location
```

---

## Prefix Averages (Concept)

Used to calculate the average of all items up to each index in a list.

Useful in time-series analysis, like calculating average returns or moving averages.

---

# 3.4: Justifying Algorithm Correctness

## Counterexamples

To disprove a universal claim, one example is enough.

> Claim: All even numbers are divisible by 4.
> Counterexample: 6 â†’ disproves the claim.

## Contrapositive

A logical technique: prove a statement by proving its **contrapositive**.

> Claim: If `a*b` is even, then `a` or `b` is even.
> Contrapositive: If both `a` and `b` are odd, then `a*b` is odd.

## Contradiction

Assume the opposite of what you want to prove.
If this leads to a contradiction, your original statement must be true.

## 3.4.3: Induction and Loop Invariants

### Induction (Mathematical Induction)

Induction is a **proof technique** used to show that a property holds for all natural numbers (or all numbers beyond a certain base case).

It consists of two steps:

#### 1. **Base Case**

Prove that the statement holds for the initial value, usually `n = 0` or `n = 1`.

#### 2. **Inductive Step**

Assume the statement holds for `n = k` (the **inductive hypothesis**) and prove it must then hold for `n = k + 1`.

> If both steps are valid, the property holds for all integers â‰¥ base case.

#### Example: Sum of First `n` Natural Numbers

Prove:

```
1 + 2 + ... + n = n(n + 1)/2
```

**Base case (n = 1):**

```
1 = 1(1 + 1)/2 = 1 âœ…
```

**Inductive step:**
Assume itâ€™s true for `n = k`:

```
1 + 2 + ... + k = k(k + 1)/2
```

Now prove it for `n = k + 1`:

```
1 + 2 + ... + k + (k + 1)
= k(k + 1)/2 + (k + 1)
= (k(k + 1) + 2(k + 1))/2
= (k + 1)(k + 2)/2 âœ…
```

Thus, by induction, the formula holds âˆ€ `n â‰¥ 1`.

---

### Strong Induction

**Strong induction** is a variant where the inductive step assumes the result holds for **all values â‰¤ k**, rather than just `k`.

Useful when the proof for `k + 1` depends on **multiple previous values**, not just the immediate predecessor.

#### Example: Every integer â‰¥ 2 can be factored into primes

* Base case: 2 is a prime âœ…
* Inductive step: assume all integers â‰¤ `k` can be written as a product of primes.

  * If `k + 1` is prime â†’ done
  * If composite â†’ can be written as `a Ã— b`, where `a, b â‰¤ k` â†’ both factorable by hypothesis

---

### Loop Invariants

A **loop invariant** is a condition that remains true **before and after each iteration** of a loop.

Used to **formally verify** the correctness of loops.

#### Proving with Loop Invariants:

1. **Initialization**: Show the invariant is true before the first iteration.
2. **Maintenance**: Show that if the invariant is true before an iteration, it remains true after.
3. **Termination**: When the loop finishes, the invariant combined with the exit condition implies correctness.

---

#### Example: Insertion Sort

**Invariant**: At the start of each iteration `i`, the subarray `A[0..i-1]` is sorted.

* **Initialization**: `i = 1`, `A[0..0]` is trivially sorted âœ…
* **Maintenance**: We insert `A[i]` into the sorted part `A[0..i-1]`, keeping it sorted âœ…
* **Termination**: When `i = n`, the whole array `A[0..n-1]` is sorted âœ…

Thus, the loop invariant proves the algorithmâ€™s correctness.

---

#### Advanced Use: Binary Search

**Invariant**: The target value, if it exists, must lie within the current search interval `[low, high]`.

* Carefully update `low` and `high` so that this invariant holds.
* Upon termination, check if the interval is empty or if the mid-value is the target.

Loop invariants can be combined with **assertions** in real code (e.g., using `assert` in Python) to make algorithms more robust and easier to verify.