## üß† Chapter 5 ‚Äì *Making Memories*: Notes & Definitions

---

### üíæ Volatile vs Non-Volatile Memory

| Type                | Definition                                                      | Examples                | Key Impact on System Design                                    |
| ------------------- | --------------------------------------------------------------- | ----------------------- | -------------------------------------------------------------- |
| **Volatile Memory** | Requires power to retain data. Loses content when power is off. | RAM (DRAM, SRAM), Cache | Fast, used for temporary data; needs backup for persistence.   |
| **Non-Volatile**    | Retains data even when power is lost.                           | ROM, Flash, SSDs, HDDs  | Used for permanent storage (OS, files). Slower but persistent. |

**Design Impact:**
Modern systems often mix both:

* Volatile for speed (e.g., running programs)
* Non-volatile for storage (e.g., saving programs and files)
  This affects boot-up time, application loading, and system power management.

---

### üß± Memory Hierarchy

A structure used to organise different memory types based on speed, cost, and size:

```
Fastest ‚Üí Slowest:
Registers > Cache (L1, L2, L3) > RAM > SSD > HDD > Tape Storage
```

* **Registers**: Closest to CPU, used for direct computation.
* **Cache**: Stores frequently accessed instructions/data to avoid RAM trips.
* **Main Memory (RAM)**: Stores running applications and data.
* **Secondary Storage**: SSDs or HDDs, long-term storage.
* **Tertiary/Offline Storage**: External backups (e.g., magnetic tape, DVDs).

**Hierarchy Benefits:**

* Keeps fast memory small and expensive, slow memory large and cheap.
* Minimises wait times by leveraging locality principles.

---

### ‚è±Ô∏è Memory Performance Strategies

**1. Access Speed**

* Measured in **latency** (time to fetch) and **bandwidth** (amount of data moved per second).
* Faster memory (like cache) has lower latency.
* Slower memory (like HDDs) has higher latency and limited bandwidth.

**2. Locality of Reference**

* **Temporal Locality**: Reuse of recently accessed data.
* **Spatial Locality**: Nearby data to recently accessed is likely to be used soon.

These principles justify cache preloading strategies.

**3. Caching**

* Temporary storage for speeding up repeated data accesses.
* Managed by hardware and sometimes software.
* May be **write-through** (write to both cache & memory) or **write-back** (write to cache only, then update memory later).

**4. Virtual Memory**

* Extends RAM using disk space (swap).
* Allows execution of programs larger than available RAM.
* Managed via **paging** and **page tables** by the OS.

---

### üß† Key Terms

| Term                  | Meaning                                                                |
| --------------------- | ---------------------------------------------------------------------- |
| **Latency**           | Delay from request to data delivery.                                   |
| **Bandwidth**         | Amount of data transferred per unit time.                              |
| **Memory Controller** | Manages communication between CPU and memory.                          |
| **DRAM**              | Dynamic RAM, must be refreshed constantly.                             |
| **SRAM**              | Static RAM, faster but more expensive.                                 |
| **Flash Memory**      | Non-volatile, used in USB drives and SSDs.                             |
| **Page Fault**        | Event where requested page isn‚Äôt in memory, must be fetched from disk. |

---

### üß© Real-World Impact

* **Faster memory = faster system**: Faster load times, smoother multitasking, quicker computations.
* **Efficient memory hierarchy** allows CPUs to stay busy instead of idling while waiting for data.
* Mobile devices often favour **non-volatile flash** for both storage and memory (due to battery efficiency).

Absolutely ‚Äî here‚Äôs an **additional section** you can tack onto your existing notes, covering **Fast Page Mode** and **Burst Mode** memory access techniques:

---

### ‚ö° Fast Page Mode & Burst Mode

These are **performance enhancements** used in DRAM to speed up data access when working with rows (or pages) of memory.

---

#### üîπ Fast Page Mode (FPM)

* **What it is:**
  A DRAM access technique that reduces latency for **accessing multiple columns** within the **same row (page)** of memory.

* **How it works:**
  Once a row is activated (row address latched), the memory controller can read multiple columns (column addresses) **without re-activating the row** each time.

* **Analogy:**
  Like opening a book to a specific page and reading multiple words without having to re-open that page every time.

* **Performance Benefit:**
  Avoids repeated row activations ‚Üí **faster successive reads/writes** within the same row.

* **Limitation:**
  Only works efficiently when data is **physically grouped** in the same row ‚Äî poor spatial locality reduces gains.

---

#### üîπ Burst Mode

* **What it is:**
  An extension of FPM where a **predefined sequence of memory locations** (usually consecutive) is read or written in **a single operation**.

* **How it works:**
  The CPU or memory controller requests a block of data (e.g. 4, 8, or 16 bytes), and the memory delivers it as a **burst** instead of one-by-one.

* **Common in:**
  Modern DRAM types like **SDRAM**, **DDR**, **GDDR** (used in graphics cards).

* **Performance Benefit:**
  High throughput ‚Äî especially useful for **instruction fetches**, **vector operations**, or **graphics rendering**, where data is used in blocks.

* **Synergy with cache:**
  Works well when prefetching cache lines since memory often needs to transfer **contiguous data**.