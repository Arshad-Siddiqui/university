# üî• Process Parallelism

Modern systems don‚Äôt just pretend to multitask ‚Äî they **truly execute tasks in parallel** using multiple CPUs and advanced threading techniques.

![Multi-Processor Multi-Threading](image-14.png)

* In a **single-processor system**, only one thread runs at a time. The CPU rapidly switches between threads, creating the **illusion** of parallelism.
* In a **multi-processor (or multicore) system**, multiple threads can execute *simultaneously* across different CPUs. This allows genuine parallel execution and much higher throughput.

---

## ‚ö° Hyper-Threading (Simultaneous Multithreading)

* **Hyper-Threading (HT)** is Intel‚Äôs implementation of **Simultaneous Multithreading (SMT)**.
* Each **physical CPU core** exposes **two (or more) logical processors** to the operating system.
* How it works:

  * The core **duplicates architectural state** (like registers) for each logical thread.
  * Execution units (ALUs, FPUs, caches) are *shared*.
  * If one thread stalls (e.g., waiting on memory), another can take over idle units, improving utilisation.

**Benefits:**

* Better use of CPU resources ‚Üí higher throughput without doubling hardware.
* Can improve performance by **20‚Äì30%** on workloads with frequent stalls.

**Limits:**

* Doesn‚Äôt give 2√ó performance (threads compete for shared execution units).
* Best for **mixed workloads** (e.g., one compute-heavy + one memory-heavy).

---

## üß† Multi-Processor System Issues

![CPU cores using different pieces of memory](image-15.png)

When multiple processors share memory, coordination becomes complex:

* **Private vs Shared Memory**

  * Some architectures give each CPU its own memory block (NUMA ‚Äì Non-Uniform Memory Access).
  * Others allow all CPUs to share one memory space (SMP ‚Äì Symmetric Multiprocessing).

* **Key Issues:**

  * **Contention:** Two CPUs may try to access the same memory at once.
  * **Cache Coherency:** Each CPU keeps a cache. If one core updates a value, other cores‚Äô caches must be updated to avoid stale data. (Handled by protocols like **MESI**).
  * **Latency Differences:** In NUMA systems, accessing ‚Äúlocal‚Äù memory is faster than ‚Äúremote‚Äù memory. OS schedulers must place threads wisely.

---

## üé≠ Uni-Processor Multi-Threading

![Uni-Processor Multi-threading](image-16.png)

* A single CPU executes multiple threads by **time-slicing**.
* Since there‚Äôs only one core, it never faces memory contention between threads ‚Äî only one instruction stream is active at a time.
* Simpler to manage, but lacks the **true parallel speedups** of multi-processor or hyper-threaded systems.

---

# ‚ú® Key Takeaways

* **Single-processor systems:** Fake parallelism with time-slicing.
* **Hyper-threading:** Efficient resource usage by overlapping thread execution inside a single core.
* **Multiprocessors:** Deliver real parallelism but must handle **memory contention** and **cache coherency**.
* **OS Role:** Schedulers must be aware of hardware topology (cores, hyperthreads, caches) to allocate threads effectively.